{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6c28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import get_nn_patients\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c64dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical #hot-encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a322f",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "Important observations:\n",
    "data for a given group (train or test) must be given to CNN into a single three-dimensional NumPy array, where the dimensions of the array are [samples, time steps, features], where sample: one input example that has 1 or more time steps with one or more features at each time step; time steps: one part of a single input example that has one or more features; feature: one of possible many observations for a given time step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e6da7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35, 857, 2), (15, 857, 2), (35, 857), (15, 857))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, _, _= get_nn_patients()\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.30, shuffle = False, stratify = None)\n",
    "x_tr.shape, x_te.shape, y_tr.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744b9342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29995, 1, 2), (29995, 4), (12855, 1, 2), (12855, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, test_size = x_tr.shape[0] * x_tr.shape[1], x_te.shape[0] * x_te.shape[1]\n",
    "trainX = x_tr.reshape(train_size,1,2)\n",
    "trainy = y_tr.reshape(train_size)\n",
    "testX = x_te.reshape(test_size,1,2)\n",
    "y_te = y_te.reshape(test_size)\n",
    "\n",
    "trainy = to_categorical(trainy)\n",
    "testy = to_categorical(y_te)\n",
    "\n",
    "trainX.shape, trainy.shape, testX.shape, testy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84168ef2",
   "metadata": {},
   "source": [
    "trainX = trainX.reshape(857,34,2)\n",
    "trainy = trainy[1,:].reshape(857)\n",
    "testX = testX.reshape(857,16,2)\n",
    "testy = testy[1,:].reshape(857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f72c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_result(preds):\n",
    "    print(classification_report(y_te,preds))\n",
    "    print(\"Balanced accuracy:\", balanced_accuracy_score(y_te,preds))\n",
    "    print(\"Accuracy:\",accuracy_score(y_te,preds))\n",
    "    plot_conf_matrix(preds, y_te, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b9d89",
   "metadata": {},
   "source": [
    "### Fitting the CNN model \n",
    "We will define the model as having two 1D CNN layers, followed by a dropout layer for regularization, then a pooling layer. It is common to define CNN layers in groups of two in order to give the model a good chance of learning features from the input data. CNNs learn very quickly, so the dropout layer is intended to help slow down the learning process and hopefully result in a better final model. The pooling layer reduces the learned features to 1/4 their size, consolidating them to only the most essential elements.\n",
    "\n",
    "After the CNN and pooling, the learned features are flattened to one long vector and pass through a fully connected layer before the output layer used to make a prediction. The fully connected layer ideally provides a buffer between the learned features and the output with the intent of interpreting the learned features before making a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebebdd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_30 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#1: 64.683\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_33 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#2: 68.012\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#3: 68.012\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_39 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#4: 67.468\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_42 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 1, 64)            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_44 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#5: 66.698\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_45 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#6: 64.481\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_48 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#7: 66.698\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_51 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#8: 64.683\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_54 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv1d_56 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_56 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#9: 67.468\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_57 (Conv1D)          (None, 1, 64)             448       \n",
      "                                                                 \n",
      " max_pooling1d_57 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_58 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_58 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 1, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,056\n",
      "Trainable params: 32,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#10: 66.698\n"
     ]
    }
   ],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features), padding = 'same'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    print(model.summary())\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
    "    return accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c159e9b",
   "metadata": {},
   "source": [
    "### Tuning the number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af04c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">p=8 #1: 46.908\n",
      ">p=8 #2: 47.694\n",
      ">p=8 #3: 61.431\n",
      ">p=8 #4: 64.761\n",
      ">p=8 #5: 44.629\n",
      ">p=8 #6: 64.761\n",
      ">p=8 #7: 64.761\n",
      ">p=8 #8: 58.366\n",
      ">p=8 #9: 61.431\n",
      ">p=8 #10: 64.761\n",
      ">p=16 #1: 64.846\n",
      ">p=16 #2: 64.216\n",
      ">p=16 #3: 64.761\n",
      ">p=16 #4: 64.846\n",
      ">p=16 #5: 64.761\n",
      ">p=16 #6: 56.912\n",
      ">p=16 #7: 64.597\n",
      ">p=16 #8: 64.846\n",
      ">p=16 #9: 64.846\n",
      ">p=16 #10: 64.846\n",
      ">p=32 #1: 61.898\n",
      ">p=32 #2: 64.683\n",
      ">p=32 #3: 64.846\n",
      ">p=32 #4: 64.683\n",
      ">p=32 #5: 64.683\n",
      ">p=32 #6: 64.683\n",
      ">p=32 #7: 64.683\n",
      ">p=32 #8: 64.683\n",
      ">p=32 #9: 64.846\n",
      ">p=32 #10: 64.846\n",
      ">p=64 #1: 67.631\n",
      ">p=64 #2: 67.468\n",
      ">p=64 #3: 67.203\n",
      ">p=64 #4: 67.242\n",
      ">p=64 #5: 67.242\n",
      ">p=64 #6: 68.012\n",
      ">p=64 #7: 68.012\n",
      ">p=64 #8: 65.228\n",
      ">p=64 #9: 66.698\n",
      ">p=64 #10: 66.698\n",
      ">p=128 #1: 67.468\n",
      ">p=128 #2: 65.251\n",
      ">p=128 #3: 68.012\n",
      ">p=128 #4: 66.659\n",
      ">p=128 #5: 66.659\n",
      ">p=128 #6: 68.012\n",
      ">p=128 #7: 66.659\n",
      ">p=128 #8: 67.203\n",
      ">p=128 #9: 66.659\n",
      ">p=128 #10: 67.203\n",
      ">p=256 #1: 67.468\n",
      ">p=256 #2: 66.659\n",
      ">p=256 #3: 66.659\n",
      ">p=256 #4: 66.278\n",
      ">p=256 #5: 66.659\n"
     ]
    }
   ],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, n_filters):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features), padding = \"same\"))\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu', padding = \"same\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # summarize mean and standard deviation\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "    # boxplot of scores\n",
    "    pyplot.boxplot(scores, labels=params)\n",
    "    pyplot.savefig('exp_cnn_filters.png')\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    "\n",
    "    # test each parameter\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repeat experiment\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "            score = score * 100.0\n",
    "            print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "            scores.append(score)\n",
    "        all_scores.append(scores)\n",
    "    # summarize results\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# run the experiment\n",
    "n_params = [8, 16, 32, 64, 128, 256]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf88c0",
   "metadata": {},
   "source": [
    "### Tuning size of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc91b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, n_kernel):\n",
    "    verbose, epochs, batch_size = 0, 15, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=n_kernel, activation='relu', input_shape=(n_timesteps,n_features), padding = \"same\"))\n",
    "    model.add(Conv1D(filters=64, kernel_size=n_kernel, activation='relu', padding = \"same\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "    print(scores, params)\n",
    "    # summarize mean and standard deviation\n",
    "    for i in range(len(scores)):\n",
    "        m, s = mean(scores[i]), std(scores[i])\n",
    "        print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "    # boxplot of scores\n",
    "    pyplot.boxplot(scores, labels=params)\n",
    "    pyplot.savefig('exp_cnn_kernel.png')\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    "\n",
    "    # test each parameter\n",
    "    all_scores = list()\n",
    "    for p in params:\n",
    "        # repeat experiment\n",
    "        scores = list()\n",
    "        for r in range(repeats):\n",
    "            score = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "            score = score * 100.0\n",
    "            print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "            scores.append(score)\n",
    "        all_scores.append(scores)\n",
    "    # summarize results\n",
    "    summarize_results(all_scores, params)\n",
    "\n",
    "# run the experiment\n",
    "n_params = [2, 3, 5, 7, 11]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014459e",
   "metadata": {},
   "source": [
    "### Running the CNN with the tuned parameters, filter = 64, kernel size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and evaluate a model\n",
    "filters = 64\n",
    "kernel_size = 11\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(n_timesteps,n_features), padding = 'same'))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding = 'same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
    "    preds = model.predict(testX)\n",
    "    classes = np.argmax(preds,axis=1)\n",
    "    return classes, accuracy\n",
    "\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    best_preds = []\n",
    "    max_score = 0\n",
    "    for r in range(repeats):\n",
    "        preds, score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_preds = preds\n",
    "    # summarize results\n",
    "    summarize_result(best_preds)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af3672",
   "metadata": {},
   "source": [
    "### Multi - headed CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f1983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-headed cnn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import concatenate\n",
    "\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # head 1\n",
    "    inputs1 = Input(shape=(n_timesteps,n_features))\n",
    "    conv1_1 = Conv1D(filters=64, kernel_size=5, activation='relu', padding = \"same\")(inputs1)\n",
    "    drop1_1 = Dropout(0.5)(conv1_1)\n",
    "    conv1_2 = Conv1D(filters=64, kernel_size=5, activation='relu', padding = \"same\")(inputs1)\n",
    "    drop1_2 = Dropout(0.5)(conv1_2)\n",
    "    flat1 = Flatten()(drop1_2)\n",
    "    # head 2\n",
    "    inputs2 = Input(shape=(n_timesteps,n_features))\n",
    "    conv2_1 = Conv1D(filters=128, kernel_size=7, activation='relu', padding = \"same\")(inputs2)\n",
    "    drop2_1 = Dropout(0.5)(conv2_1)\n",
    "    conv2_2 = Conv1D(filters=128, kernel_size=7, activation='relu', padding = \"same\")(inputs2)\n",
    "    drop2_2 = Dropout(0.5)(conv2_2)\n",
    "    flat2 = Flatten()(drop2_2)\n",
    "    # head 3\n",
    "    inputs3 = Input(shape=(n_timesteps,n_features))\n",
    "    conv3_1 = Conv1D(filters=256, kernel_size=11, activation='relu', padding = \"same\")(inputs3)\n",
    "    drop3_1 = Dropout(0.5)(conv3_1)\n",
    "    conv3_2 = Conv1D(filters=256, kernel_size=11, activation='relu', padding = \"same\")(inputs3)\n",
    "    drop3_2 = Dropout(0.5)(conv3_2)\n",
    "    flat3 = Flatten()(drop3_2)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(100, activation='relu')(merged)\n",
    "    outputs = Dense(n_outputs, activation='softmax')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # save a plot of the model\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit([trainX,trainX,trainX], trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate([testX,testX,testX], testy, batch_size=batch_size, verbose=0)\n",
    "    return (accuracy)\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    return summarize_result(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ea8db",
   "metadata": {},
   "source": [
    "### Trying with the two different augmentation (small and big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9180ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "radars, mats, patients, x_small, x_big, y_small, y_big = get_nn_patients(divided = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59164e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small.shape , x_big.shape , y_small.shape , y_big.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a8290",
   "metadata": {},
   "source": [
    "#### CNN with small mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6055d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _, _= get_nn_patients(divided=True)\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "x_tr.shape, x_te.shape, y_tr.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac88890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size = x_tr.shape[0] * x_tr.shape[1], x_te.shape[0] * x_te.shape[1]\n",
    "trainX = x_tr.reshape(train_size,1,2)\n",
    "trainy = y_tr.reshape(train_size)\n",
    "testX = x_te.reshape(test_size,1,2)\n",
    "testy = y_te.reshape(test_size)\n",
    "\n",
    "trainy = to_categorical(trainy)\n",
    "testy = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and evaluate a model\n",
    "filters = 64\n",
    "kernel_size = 11\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(n_timesteps,n_features), padding = 'same'))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding = 'same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
    "    return accuracy\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_result(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fceb66c",
   "metadata": {},
   "source": [
    "#### CNN with large mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, x, y= get_nn_patients(divided=True)\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "x_tr.shape, x_te.shape, y_tr.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size = x_tr.shape[0] * x_tr.shape[1], x_te.shape[0] * x_te.shape[1]\n",
    "trainX = x_tr.reshape(train_size,1,2)\n",
    "trainy = y_tr.reshape(train_size)\n",
    "testX = x_te.reshape(test_size,1,2)\n",
    "testy = y_te.reshape(test_size)\n",
    "\n",
    "trainy = to_categorical(trainy)\n",
    "testy = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and evaluate a model\n",
    "filters = 64\n",
    "kernel_size = 11\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(n_timesteps,n_features), padding = 'same'))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding = 'same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_result(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168942d",
   "metadata": {},
   "source": [
    "### Raw Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _, _= get_nn_patients(raw=True)\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "x_tr.shape, x_te.shape, y_tr.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445587a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te = x_tr[:,:,[0,2,5]], x_te[:,:,[0,2,5]]\n",
    "train_size, test_size = x_tr.shape[0] * x_tr.shape[1], x_te.shape[0] * x_te.shape[1]\n",
    "trainX = x_tr.reshape(train_size,1,3)\n",
    "trainy = y_tr.reshape(train_size)\n",
    "testX = x_te.reshape(test_size,1,3)\n",
    "testy = y_te.reshape(test_size)\n",
    "\n",
    "trainy = to_categorical(trainy)\n",
    "testy = to_categorical(testy)\n",
    "\n",
    "trainX.shape, testX.shape, trainy.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5593f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and evaluate a model\n",
    "filters = 64\n",
    "kernel_size = 11\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(n_timesteps,n_features), padding = 'same'))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', padding = 'same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_result(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d563d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
